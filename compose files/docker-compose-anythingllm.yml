# AnythingLLM Only - Cloud LLM
# Use this if you prefer cloud LLM providers (OpenAI, Anthropic, etc.)
# Requirements: API key from your preferred provider
# No GPU needed, but you'll pay per API call

services:
  anythingllm:
    image: mintplexlabs/anythingllm:latest
    hostname: anythingllm
    container_name: anythingllm
    ports: 
      - "3001:3001"
    environment:
      - STORAGE_DIR=/app/server/storage
      - DISABLE_TELEMETRY=true
    volumes:
      - ${ANYTHINGLLM_DATA_DIR:-./anythingllm-data}:/app/server/storage
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - app_network

  jobcollector:
    build:
      context: ../.
      dockerfile: Dockerfile
    image: drjp81/linkedinscrape:latest
    container_name: jobcollector
    environment:
      # Collector parameters
      - SITE_NAME=${SITE_NAME:-indeed,linkedin,glassdoor}
      - SEARCH_TERMS=${SEARCH_TERMS:-Azure,devops}
      - LOCATION=${LOCATION:-Canada}
      - RESULTS_WANTED=${RESULTS_WANTED:-20}
      - HOURS_OLD=${HOURS_OLD:-24}
      - COUNTRY_INDEED=${COUNTRY_INDEED:-canada}
      - LINKEDIN_FETCH_DESCRIPTION=${LINKEDIN_FETCH_DESCRIPTION:-true}
      - DATA_DIR=/DATA
      - CANDIDATE_NAME=${CANDIDATE_NAME:-John Doe}
      # AnythingLLM parameters (Ollama disabled)
      - ANLLM_API_KEY=${ANLLM_API_KEY}
      - ANLLM_API_WORKSPACE=${ANLLM_API_WORKSPACE:-job-searching}
      - ANLLM_API_BASE=${ANLLM_API_BASE:-http://anythingllm:3001}
      - RETRIES=${RETRIES:-3}
      - TIMEOUT_MINUTES=${TIMEOUT_MINUTES:-5}
      # Disable Ollama
      - OLLAMA_BASE=
      - SCORER_MODEL=
      - EMBED_MODEL=
    volumes:
      - ${DATA_DIR:-./data}:/DATA
    depends_on:
      anythingllm:
        condition: service_healthy
    restart: on-failure
    networks:
      - app_network

networks:
  app_network:
    driver: bridge