# =============================================================================
# Job Search Automation - Environment Configuration
# =============================================================================
# Copy this file to .env and customize for your setup.
# 
# IMPORTANT: Different docker-compose files use different variables.
# See README-COMPOSE.md for which variables apply to your chosen configuration.
#
# =============================================================================

# -----------------------------------------------------------------------------
# DATA PERSISTENCE
# -----------------------------------------------------------------------------
# Where to store job data, resumes, and reports
# This should be a "real" absolute path on your host system
DATA_DIR=/DATA

# Where Ollama stores model data (only for Ollama configs)
# Leave as-is unless you want models stored elsewhere
OLLAMA_DATA_DIR=/OLLAMADATA/ollama-data

# Where AnythingLLM stores workspace data (only for AnythingLLM configs)
ANYTHINGLLM_DATA_DIR=/ANYTHINGLLMDATADIR/anythingllm-data

# -----------------------------------------------------------------------------
# JOB SCRAPING CONFIGURATION
# -----------------------------------------------------------------------------
# Which job boards to scrape (comma-separated)
# Options: indeed, linkedin, glassdoor, google
SITE_NAME=indeed,linkedin,glassdoor

# What to search for (comma-separated list)
# Each term is scraped separately, results are combined
SEARCH_TERMS="Azure DevOps,Platform Engineer,Site Reliability Engineer"

# Geographic location filter
LOCATION=Canada

# Maximum results to fetch per search term
RESULTS_WANTED=50

# Only get jobs posted within this many hours
HOURS_OLD=24

# Indeed-specific country code
# Options: usa, canada, uk, australia, etc.
COUNTRY_INDEED=canada

# Fetch full job descriptions from LinkedIn (slower but more complete)
# Options: true, false
LINKEDIN_FETCH_DESCRIPTION=true

# -----------------------------------------------------------------------------
# CANDIDATE INFORMATION
# -----------------------------------------------------------------------------
# Your name (used in scoring context)
CANDIDATE_NAME="Your Name"

# -----------------------------------------------------------------------------
# OLLAMA CONFIGURATION (for Ollama-only and Both-backends configs)
# -----------------------------------------------------------------------------
# Ollama API endpoint (leave as-is for Docker)
OLLAMA_BASE=http://ollama:11434

# Model to use for scoring
# Recommended: qwen2.5:7b-instruct (best JSON reliability)
# Alternatives: llama3.2:3b-instruct-q6_K (faster, less VRAM)
SCORER_MODEL=qwen2.5:7b-instruct

# Embedding model for resume chunking (optional, for RAG)
# EMBED_MODEL=nomic-embed-text:v1.5 (deprecated)

# Path to your resume text file (inside container)
# Place your resume at /DATA/resume/resume.txt on host
CANDIDATE_RESUME_PATH=/DATA/resume/resume.txt

# Model temperature (0.0-1.0, lower = more consistent)
TEMPERATURE=0.3

# Maximum context length in tokens
# Depends on GPU VRAM:
#   6GB VRAM: 8192
#   8GB VRAM: 16384
#   12GB+ VRAM: 32768
CONTEXT_LENGTH=32768

# Resume chunking parameters (for RAG)
K_RESUME_SNIPPETS=6
RESUME_CHUNK_SIZE=900
RESUME_CHUNK_OVERLAP=150

# -----------------------------------------------------------------------------
# SCORING CRITERIA (for Ollama-only and Both-backends configs)
# -----------------------------------------------------------------------------
# Must-have skills/keywords (comma-separated)
# High weight in scoring algorithm
MUST_HAVES=Azure,DevOps,CI/CD,Remote

# Nice-to-have skills/keywords (comma-separated)
# Medium weight in scoring algorithm
NICE_TO_HAVES=Kubernetes,Terraform,Python,PowerShell,Docker

# Exclusion keywords (comma-separated)
# Jobs containing these get score penalties
EXCLUSIONS=SAP,Mainframe,COBOL

# Preferred locations (comma-separated)
# Jobs outside these regions get penalties
LOCALE=Montreal,Quebec,Canada,Remote-Canada

# Language preference
# Options: fr, en, either, mixed
LANG_PREF=either

# Target seniority level
# Options: junior, mid, senior, lead
# Jobs at wrong level get penalties
SENIORITY_TARGET=senior

# -----------------------------------------------------------------------------
# ANYTHINGLLM CONFIGURATION (for AnythingLLM-only and Both-backends configs)
# -----------------------------------------------------------------------------
# AnythingLLM API endpoint (leave as-is for Docker)
ANLLM_API_BASE=http://anythingllm:3001

# Your workspace slug (visible in URL: /workspace/YOUR-SLUG)
ANLLM_API_WORKSPACE=job-searching

# Your AnythingLLM API key
# Generate this in AnythingLLM UI: Settings → API Keys → Create New
# IMPORTANT: Keep this secret!
ANLLM_API_KEY=YOUR-API-KEY-HERE

# Number of retry attempts for failed API calls
RETRIES=3

# Timeout for each API request (minutes)
# Should be >= your model unload timeout in AnythingLLM
TIMEOUT_MINUTES=5

# AnythingLLM exposed port (if you change this, update ANLLM_API_BASE too)
ANYTHINGLLM_PORT=3001

# Storage directory for AnythingLLM (inside container, don't change)
STORAGE_DIR=/app/server/storage

# =============================================================================
# CONFIGURATION CHEAT SHEET
# =============================================================================
#
# Ollama-only configs need:
#   - DATA_DIR
#   - SITE_NAME, SEARCH_TERMS, LOCATION, etc. (scraping config)
#   - OLLAMA_BASE, SCORER_MODEL, CANDIDATE_RESUME_PATH
#   - MUST_HAVES, NICE_TO_HAVES, EXCLUSIONS, etc. (scoring criteria)
#
# AnythingLLM-only configs need:
#   - DATA_DIR
#   - SITE_NAME, SEARCH_TERMS, LOCATION, etc. (scraping config)
#   - ANLLM_API_BASE, ANLLM_API_WORKSPACE, ANLLM_API_KEY
#
# Both-backends configs need:
#   - DATA_DIR
#   - SITE_NAME, SEARCH_TERMS, LOCATION, etc. (scraping config)
#   - OLLAMA_BASE, SCORER_MODEL, CANDIDATE_RESUME_PATH
#   - MUST_HAVES, NICE_TO_HAVES, EXCLUSIONS, etc. (scoring criteria)
#   - ANLLM_API_BASE, ANLLM_API_WORKSPACE, ANLLM_API_KEY (optional, for fallback)
#
# =============================================================================